{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df9a367",
   "metadata": {},
   "source": [
    "# Predicting Wavebands with a cGAN\n",
    "One of the most exciting applications of deep learning is image-to-image translation which includes tasks such as image colourisation and super resolution. This task needed a lot of human input and hardcoding several years ago but, with the development of deep learning over recent years, the whole process can be done end-to-end with the power of machine learning. \n",
    "This task will be focused on predicting longer waveband data, *2.4-5.0µm*, from the recent CEERS JWST data release 0.5 from short waveband data, *0.5-2.4µm*, using a conditional Generative Adversarial Network (cGAN). The stategy follows closely to that used in [_**Image-to-Image Translation with Conditional Adversarial Networks**_](https://arxiv.org/abs/1611.07004) which may also be known by *pix2pix* where a general solution to many image-to-image translation problems is proposed, one being image colourisation. In this approach, two losses are used, namely an L1 loss, which makes this task a regression task, and an adversarial (GAN) loss, which helps to solve the problem in an unsupervised manner. \n",
    "\n",
    "### The World of GANs ###\n",
    "The architecture used in this problem is a conditional GAN which uses an extra loss function, the L1 loss. It is useful to understand the setup of a GAN.\n",
    "In a GAN, there is a Generator and a Discriminator network which work together to solve a problem. In this model, the Generator network takes a 3-channel input, composed of the stacked short waveband data, and produces a 3-channel output, that of the long waveband filters. The Discriminator network takes the generated long waveband data and decides whether it is real or fake. Naturally, the Discriminator needs to see real inputs - those that are not produced by the Generator, and should learn that they are real. \n",
    "The condition on this model is that both the Generator and Discriminator *see* the input.\n",
    "Let's take a further look into what the cGAN is doing. Consider _**x**_ to be the input to the network, _**z**_ as the input noise for the Generator, and _**y**_ the output we expect from the Generator. Let G and D denote the Generator and Discriminator networks, respectively. The loss of the cGAN can be described via:\n",
    "\\\n",
    "![cGAN-loss](images/cGAN-loss.png).\n",
    "\\\n",
    "Note that _**x**_ is the condition that we have introduced and it is seen by both networks. Also note that we are *not* feeding an *n*-dimensional vector of random noise to the Generator, which is common in machine learning networks, since the noise is introduced in the form of dropout layers in the Generator network.\n",
    "\n",
    "#### Loss Function ####\n",
    "The goal is optimisation and, more specifically, to minimise the loss. The above loss function helps to produce an output that seems real, however, to further steer the model in the right direction and to introduce some supervision into this task, we combine the above loss with the L1 loss (which can be also known as the mean absolute error):\n",
    "\\\n",
    "![L1 loss](images/L1-loss.png).\n",
    "\\\n",
    "The model will learn features from the data using the L1 loss alone, but it will be conservative and take an average which will reduce the L1 loss as much as possible (this can be compared to the blurring effect of L1 or L2 loss in a super resolution task). Combining the adversarial loss with the L1 loss gives the overall loss function for the model:\n",
    "\\\n",
    "![loss](images/Loss.png),\n",
    "\\\n",
    "where *λ* is the coefficient to balance the contribution of the two losses to the final loss. Note that the discriminator loss does not involve the L1 loss. \n",
    "\n",
    "### Implementing the cGAN ###\n",
    "The cGAN is implemented using Pytorch; a convenient package for machine learning models. This example uses ~ 1900 input data in the form of the galaxy cutouts extracted from the CEERS JWST data release 0.5. You are welcome to train the network on your own data provided it is in the same format. This is discussed in the README page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73463f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "from astropy.io import fits\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\\..*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a62d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to working directory (use directory where your data is saved)\n",
    "home = \"/Users/ruby/Documents/Python Scripts/Filters/\"\n",
    "# list of filters which is then split into blue filters and red filters\n",
    "filters = ['F115W/', 'F150W/', 'F200W/', 'F277W/', 'F356W/', 'F444W/']\n",
    "nbands = len(filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a76765",
   "metadata": {},
   "source": [
    "The data that we extracted in the previous notebooks must be processed before feeding to the network. Since large pixel values will cause long training times, we choose to normalise the data appropriately across all 6 wavebands. To do this, we plot a histogram of each data file we previously extracted for each waveband and take the lower and upper $10\\%$ percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff728db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_Percentiles(path, filtername):\n",
    "    file_list = glob.glob(f\"{path}/{filtername}/*.fits\")\n",
    "    bins = np.linspace(1e-9, np.log10(5), 100)\n",
    "    hists = []\n",
    "    for i in file_list:\n",
    "        with fits.open(i) as fitsfile:\n",
    "            img = np.log10(fitsfile[0].data)\n",
    "            hist, bins = np.histogram(img, bins=bins)\n",
    "            hists.append(hist)\n",
    "    hists_sum = np.sum(hists, axis=0)\n",
    "    total = hists_sum.sum()\n",
    "    lower = 0.\n",
    "    upper = 0.\n",
    "    for i in range(len(hists_sum)):\n",
    "        lower += hists_sum[i]\n",
    "        if lower > .1*total:\n",
    "            percentile_lower = bins[i]\n",
    "            break\n",
    "    for j in range(len(hists_sum)):\n",
    "        upper += hists_sum[-j]\n",
    "        if upper > 0.1*total:\n",
    "            percentile_upper = bins[-(j+1)]\n",
    "            break\n",
    "    return percentile_lower, percentile_upper, hists_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a52f2",
   "metadata": {},
   "source": [
    "Now, we create a list to append the percentiles of each waveband to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a277768f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9h/r1jl5z8j0252hq0p27nzdc_40000gp/T/ipykernel_83984/2132027461.py:7: RuntimeWarning: invalid value encountered in log10\n",
      "  img = np.log10(fitsfile[0].data)\n",
      "/var/folders/9h/r1jl5z8j0252hq0p27nzdc_40000gp/T/ipykernel_83984/2132027461.py:7: RuntimeWarning: divide by zero encountered in log10\n",
      "  img = np.log10(fitsfile[0].data)\n"
     ]
    }
   ],
   "source": [
    "waveband_percentiles = []\n",
    "for filter_ in filters:\n",
    "    lower, upper, sum1 = Filter_Percentiles(home, filter_)\n",
    "    waveband_percentiles.append([lower, upper])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cdbad7",
   "metadata": {},
   "source": [
    "Since *waveband_percentiles* contains the information of the lower and upper extreme percentiles of the wavebands in the order $F115W...F444W$, we can set the lower and upper percentiles for each waveband individually to use for the normalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd31943",
   "metadata": {},
   "outputs": [],
   "source": [
    "f115w_lower, f115w_upper = waveband_percentiles[0][0], waveband_percentiles[0][1]\n",
    "f150w_lower, f150w_upper = waveband_percentiles[1][0], waveband_percentiles[1][1]\n",
    "f200w_lower, f200w_upper = waveband_percentiles[2][0], waveband_percentiles[2][1]\n",
    "f277w_lower, f277w_upper = waveband_percentiles[3][0], waveband_percentiles[3][1]\n",
    "f356w_lower, f356w_upper = waveband_percentiles[4][0], waveband_percentiles[4][1]\n",
    "f444w_lower, f444w_upper = waveband_percentiles[5][0], waveband_percentiles[5][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38881a8",
   "metadata": {},
   "source": [
    "Before we create our dataset and dataloaders, both the train and test data need to be normalised for the model to train. The data are normalised using the lower and upper percentiles that we calculated above and will use whilst creating each dataset. The below function defines a Min-Max normalisation with the lower and upper bounds being the lower and upper percentiles, respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a5144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalise(data, lower, upper):\n",
    "    return ((data - lower)/ (upper - lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7f60f",
   "metadata": {},
   "source": [
    "To extract predictions from the network to create SED (*Spectral Energy Distribution*) plots, we will have to inverse this normalisation. The following function is the rearranged equation of the normalisation function we have used above. We will use this after training/testing the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2771e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inverse(data, lower, upper):\n",
    "    return (data * (upper - lower) + lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d7c16",
   "metadata": {},
   "source": [
    "#### Dataset and Dataloaders ####\n",
    "Here we create the dataset for our model. First, the data must be transformed to the correct size for the model (256x256). We do this because the network will take relatively small kernels sizes (of size $4\\times4$) meaning that it has a small receptive field. Taking too large an image size will result in a narrow network which is difficult to train Additionally, the layers within the U-Net are easier to design when the images are a factor of 2 in size, thus resizing the inputs to $256=2^8$ allows for easy construction of the convolution layers.\n",
    "The data in each waveband file are read, appended as an input for short wavebands (as a label for long wavebands) and normalised using the above function. Both the inputs and labels are transformed to a tensor of shape [(channel, height, width)] before being resized to 256x256. We then split the dataset into training and testing, using 90% of the data to train and 10% for testing, before creating the dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6b695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "# create the dataset which will be split into train and test\n",
    "class FilterDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        ''' path = path to directory containing fits files '''\n",
    "        self.path = path\n",
    "        self.transforms_inputs = torch.nn.Sequential(transforms.Resize((SIZE, SIZE)))\n",
    "                                                     \n",
    "        self.transforms_labels = torch.nn.Sequential(transforms.Resize((SIZE, SIZE)))\n",
    "                                                    \n",
    "        self.f115w_path = path+'F115W/'\n",
    "        self.f150w_path = path+'F150W/'\n",
    "        self.f200w_path = path+'F200W/'\n",
    "        self.f277w_path = path+'F277W/'\n",
    "        self.f356w_path = path+'F356W/'\n",
    "        self.f444w_path = path+'F444W/'\n",
    "        self.l1 = len(os.listdir(self.f115w_path)) - 1 \n",
    "    \n",
    "    def __len__(self):\n",
    "        # return total number of fits files for the galaxy cutouts consistent\n",
    "        # with the 'idx' in the __getitem__ method\n",
    "        return (self.l1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get the name of the fits file\n",
    "        name = str(idx)+'galaxy_cutout.fits'\n",
    "        # for each input filter, get each fits file, open and extract the \n",
    "        # first row (only row which is 'SCI' data) and normalise before\n",
    "        # formatting into an array\n",
    "        hdu1 = fits.open(self.f115w_path+name)[0]\n",
    "        data1 = Normalise(hdu1.data, f115w_lower, f115w_upper)\n",
    "        hdu2 = fits.open(self.f150w_path+name)[0]\n",
    "        data2 = Normalise(hdu2.data, f150w_lower, f150w_upper)\n",
    "        hdu3 = fits.open(self.f200w_path+name)[0]\n",
    "        data3 = Normalise(hdu3.data, f200w_lower, f200w_upper)\n",
    "        # now the same for the label filters as    \n",
    "        hdu4 = fits.open(self.f277w_path+name)[0]\n",
    "        data4 = Normalise(hdu4.data, f277w_lower, f277w_upper)\n",
    "        hdu5 = fits.open(self.f356w_path+name)[0]\n",
    "        data5 = Normalise(hdu5.data, f356w_lower, f356w_upper)\n",
    "        hdu6 = fits.open(self.f444w_path+name)[0]\n",
    "        data6 = Normalise(hdu6.data, f444w_lower, f444w_upper)\n",
    "        \n",
    "        # stack the input filters (f115w, f150w, f200w)\n",
    "        inputs = np.dstack((data1, data2, data3)).astype(\"float32\")\n",
    "        # reformat the inputs as tensors\n",
    "        inputs = transforms.ToTensor()(inputs)\n",
    "        # reshape the tensor to [C, H, W] for the transform to work\n",
    "        inputs = inputs.permute(0, 1, 2)\n",
    "        # now resize the inputs to 256x256\n",
    "        inputs = self.transforms_inputs(inputs)\n",
    "        \n",
    "        # do the same for the labels\n",
    "        labels = np.dstack((data4, data5, data6)).astype(\"float32\")\n",
    "        labels = transforms.ToTensor()(labels)\n",
    "        labels = labels.permute(0, 1, 2)\n",
    "        labels = self.transforms_labels(labels)\n",
    "        \n",
    "        # return the inputs with corresponding labels in a dictionary\n",
    "        return {'Inputs': inputs, 'Labels': labels}\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c2f7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.FilterDataset object at 0x1042c9ca0>\n"
     ]
    }
   ],
   "source": [
    "dataset = FilterDataset(path=home)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d410d4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 13\n"
     ]
    }
   ],
   "source": [
    "# split the generated dataset into training and testing \n",
    "BATCH_SIZE = 16                                     # set the batch size\n",
    "VALIDATION_SPLIT = 0.1                              # set the validation split of 10%\n",
    "SHUFFLE_DATASET = True                              # shuffle the training data only\n",
    "RANDOM_SEED = 42                                    # randomly shuffle through indexed dataset\n",
    "\n",
    "# create indices for training and test split\n",
    "DATASET_SIZE = len(dataset)\n",
    "# list the dataset with an index for each entry\n",
    "indices = list(range(DATASET_SIZE))\n",
    "# define the split for the dataset\n",
    "split = int(np.floor(DATASET_SIZE * VALIDATION_SPLIT))\n",
    "if SHUFFLE_DATASET:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "# split the dataset into training and testing \n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# create data samplers and dataloaders\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "# create dataloaders\n",
    "trainloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "testloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "print(len(trainloader), len(testloader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c06641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 256, 256]) torch.Size([16, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "inputs_, labels_ = data['Inputs'], data['Labels']\n",
    "print(inputs_.shape, labels_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac9260",
   "metadata": {},
   "source": [
    "#### Generator Architecture ####\n",
    "The following code implements a U-Net to be used as the Generator for the cGAN. It produces the U-Net from the middle part, down in the U shape, and adds down-sampling and up-sampling modules to the left and the right of the middle module, respectively, at every iteration until it reaches the input module and output module:\n",
    "\\\n",
    "![U-Net](images/U-Net.png).\n",
    "\\\n",
    "The blue boxes show the order in which the related modules are built. The U-Net shown in the following code has more layers than depicted above. In the code, we go 8 layers down, so, starting with a 256x256 input, we will get a 1x1 (256/2⁸) image in the middle of the U-Net which then gets up-sampled to produce a 256x256 image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccbe4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net module\n",
    "class UnetBlock(nn.Module):\n",
    "    ''' U-Net is used as the generator of the GAN.\n",
    "        Creates the U-Net from the middle part down and adds down-sampling and\n",
    "        up-sampling modules to the left and right of the middle module.\n",
    "        8 layers down so start with a 256x256 tensor with 3 channels, down-sample \n",
    "        to a 1x1 tensor, then up-sample to a 256x256 tensor with 3 channels. '''\n",
    "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
    "                 innermost=False, outermost=False):\n",
    "        ''' ni = number of filters in the inner convolution layer\n",
    "            nf = number of filters in the outer convolution layer\n",
    "            input_c = number of input channels (= 3)\n",
    "            submodule = previously defined submodules\n",
    "            dropout = not using dropout layers '''\n",
    "        super().__init__()\n",
    "        self.outermost = outermost\n",
    "        if input_c is None: input_c = nf\n",
    "        downconv = nn.Conv2d(in_channels=input_c, out_channels=ni, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(ni)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = nn.BatchNorm2d(nf)\n",
    "        \n",
    "        if outermost: # if this module is the outermost module i.e downsampling\n",
    "            upconv = nn.ConvTranspose2d(in_channels=ni*2, out_channels=nf, kernel_size=4, stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost: # if this module is the innermost module, i.e upsampling\n",
    "            upconv = nn.ConvTranspose2d(in_channels=ni, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(in_channels=ni*2, out_channels=nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else: # add skip connections\n",
    "            return torch.cat([x, self.model(x)], dim=1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    ''' U-Net based generator.'''\n",
    "    def __init__(self, input_c=3, output_c=3, n_down=8, num_filters=64):\n",
    "        ''' input_c = number of input channels (= 3)\n",
    "            output_c = number of output channels (= 3)\n",
    "            n_down = number of downsamples: we start with 256x256 and after \n",
    "                                            8 layers, we have a 1x1 tensor at the bottleneck.\n",
    "            num_filters = number of filters in the last convolution layer. '''\n",
    "        super().__init__()\n",
    "        unet_block = UnetBlock(num_filters*8, num_filters*8, innermost=True)\n",
    "        for _ in range(n_down - 5):\n",
    "            # adds intermediate layers with num_filters * 8 filters\n",
    "            unet_block = UnetBlock(num_filters*8, num_filters*8, submodule=unet_block, dropout=True)\n",
    "        out_filters = num_filters*8\n",
    "        for _ in range(3):\n",
    "            # gradually reduce the number of filters to num_filters\n",
    "            unet_block = UnetBlock(out_filters//2, out_filters, submodule=unet_block)\n",
    "            out_filters //= 2\n",
    "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ee72f",
   "metadata": {},
   "source": [
    "#### Discriminator Architecture ####\n",
    "The following code describes the architecture of the Discriminator which implements a model by stacking blocks of Convolution - Batch Normalisation - Leaky ReLU to decide whether the input is real or fake. The first and last blocks do *not* use batch normalisation and the last block has *no* activation function (because the activation function will be embedded in the loss function we will use later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3444d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a Patch-Discriminator\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    ''' Patch discriminator stacks blocks of convolution-batchnorm-leakyrelu \n",
    "        to decide whether the input tensor is real or fake. \n",
    "        Patch discriminator outputs one number for every NxN pixels of the input\n",
    "        and decides whether each \"patch\" is real/fake. \n",
    "        Patches will be 70 by 70. '''\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        ''' input_c = number of input channels (= 3)\n",
    "            num_filters = number of filters in last convolution layer\n",
    "            n_down = number of layers '''\n",
    "        super().__init__()\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
    "        # use if statement to take care of not using a stride of 2 in the last block of the loop\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i+1), s=1 if i == (n_down-1) else 2) for i in range(n_down)]\n",
    "        # do not use normalisation or activation for the last layer of the model\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 3, s=1, norm=False, act=False)] # ouput 3 channel prediction\n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    # make a separate method for the repetitive layers\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
    "        ''' norm = batch norm layer\n",
    "        act = apply activation '''\n",
    "        layers = [nn.Conv2d(in_channels=ni, out_channels=nf, kernel_size=k, stride=s, padding=p, bias=not norm)]\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce423c1",
   "metadata": {},
   "source": [
    "Look at its blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a4f3f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchDiscriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(512, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PatchDiscriminator(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac15823",
   "metadata": {},
   "source": [
    "And the shape of its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57f111c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 30, 30])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = PatchDiscriminator(3)\n",
    "input_ = torch.randn(16, 3, 256, 256) # [Batch, Channels, Height, Width]\n",
    "output = discriminator(input_)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9652294",
   "metadata": {},
   "source": [
    "Notice that we are using a Patch Discriminator. What is a Patch Discriminator?\n",
    "\\\n",
    "In a vanilla discriminator, the model outputs one number (a scalar), which represents how much the model thinks the input is real (or fake). In a patch discriminator, the model outputs one number for every patch of ~70x70 pixels of the input and for each of them, decides whether it is real (or fake), separately. Using such a model for this task is reasonable because the local changes that the model needs to make are important. Making a decision on the whole input regarding whether it is real or fake, as in a vanilla discriminator, cannot take care of the subtleties of this task. \n",
    "Here, the model's output shape is 30x30 but that does not mean that the patches are of size 30x30. The actual patch size is obtained when we compute the [_**receptive field**_](https://www.researchgate.net/figure/The-PatchGAN-discriminator-where-the-receptive-field-of-the-discriminator-is-N-N-Gz_fig5_336431839) of each of these 900 (30x30=900) output numbers, which will be 70 by 70 in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d299b0",
   "metadata": {},
   "source": [
    "#### GAN Loss ####\n",
    "We need to initiate the adversarial GAN loss for the final model. Below, in the **init** function, we decide what type of loss we will use (\"vanilla\") and we register some constant tensors as the \"real\" and \"fake\" labels, representing a tensor of all 1's or all 0's, respectively. It fills these tensors when we call the module and computes the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f91445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique loss function for the GAN \n",
    "class GANLoss(nn.Module):\n",
    "    ''' Calculates the GAN loss of the final model.\n",
    "        Uses a \"vanilla\" loss and registers constant tensors for the real\n",
    "        and fake labels. Returns tensors full of zeros or ones to compute the loss'''\n",
    "        \n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer(name='real_label', tensor=torch.tensor(real_label))\n",
    "        self.register_buffer(name='fake_label', tensor=torch.tensor(fake_label))\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss() # binary cross entropy loss\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss() \n",
    "        \n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds) # expand to the same size as predictions\n",
    "    \n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac5c266",
   "metadata": {},
   "source": [
    "#### Model Initialisation ####\n",
    "Here, we initialise the weights of the model with a mean, µ=0, and a standard deviation, σ=0.02. We also initialise the entire model by sending to model to the device (I'm using \"cuda\" but you can choose which device you wish to use) and initialising its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3be16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilise the weights of the model here\n",
    "def Init_Weights(net, init='norm', gain=.02):\n",
    "    ''' Image-to-image translation paper state that the model is initialised \n",
    "        with a mean of 0.0 and std 0.02'''\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                # fills tensor with values drawn from normal distribution N(mean,std^2)\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier': \n",
    "                # fills input tensor with avlues sampled from N(0,std^2)\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming': \n",
    "                # resulting tensor has values sampled from N(0,std^2)\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "            \n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(tensor=m.bias.data, val=0.0) # tensor filled with zeros\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1.0, gain)\n",
    "            nn.init.constant_(tensor=m.bias.data, val=0.0)\n",
    "    \n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialised with {init} initialisation\")\n",
    "    return net\n",
    "\n",
    "def Init_Model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = Init_Weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a0abd",
   "metadata": {},
   "source": [
    "#### The Model ####\n",
    "The following code is a class that brings all the previous sections together and implements the methods required to train the model.\n",
    "\\\n",
    "Firstly, in the **init** function, we define the Generator and Discriminator networks using the above classes that we defined and we initialise them using the **Init_Model** function above. We define the two loss functions that we have discussed and the optimisers of both the Generator and Discriminator (we use the [_**Adam**_](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimiser which is similar to applying the Gradient Descent Method). It is also worth noting the learning rate of both the Generator and Discriminator, which have a learning rate of *lr_G=lr_D=0.0002*. This learning rate is carefully selected; a learning rate that is too large might lead to a divergent solution, and a learning rate that is too small will take unneccessarily long and eventually end up in a local minimum. A learning rate of *0.0002* is sufficient.\n",
    "\\\n",
    "The majority of the computations are done in the **optimise** method of this class. First, and only once per iteration (batch of the training set), we call the module's forward method and store the outputs in the *fake_fits* variable of the class. \n",
    "\\\n",
    "The Discriminator is trained first using the **backward_D** method, where we feed the *fake* data produced by the Generator to the Discriminator (we detach them from the Generator's graph to make sure they act as a constant to the Discriminator) and label the data as *fake*. A batch of *real* data from the training set is then fed to the Discriminator and labelled as *real*. The losses for the *fake* and *real* data is calculated and added togther, the average between the two taken, and the backward method called on the final loss. The Generator is then trained. In the **backward_G** method, the Discriminator is fed the *fake* data and we try to fool the Discriminator by assigning *real* labels and calculating the adversarial (GAN) loss. As previously mentioned, the L1 loss is also used to compute the distance between the predicted output and the target output, which is then multipled by the coefficient *λ* (where we have set λ=100) to balance the two losses before adding this loss to the adversarial loss. \n",
    "\\\n",
    "The backward method of the loss is finally called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "618ed079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to initialise the main GAN network\n",
    "class GANModel(nn.Module):\n",
    "    ''' Initialises the model defining the generator and discriminator in the\n",
    "        __init__ function using the functions given and initialises the loss\n",
    "        functions '''\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4, beta1=.5, beta2=.999, lambda_L1=100.): \n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambda_L1 = lambda_L1\n",
    "        \n",
    "        if net_G is None:\n",
    "            self.net_G = Init_Model(Unet(input_c=3, output_c=3, n_down=8, num_filters=64), self.device)\n",
    "        else:\n",
    "            self.net_G.to(self.device)\n",
    "        \n",
    "        self.net_D = Init_Model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "        self.GAN_loss = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1_loss = nn.L1Loss()\n",
    "        # initialise optimisers for generator and discriminator  \n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1,beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1,beta2))\n",
    "        # initialise empty lists to append the generator and discriminator losses to\n",
    "        self.generator_losses, self.discriminator_losses = [], []\n",
    "    \n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "        \n",
    "    def setup_input(self, data):\n",
    "        # Get the input data and labels\n",
    "        self.inputs = data['Inputs'].to(self.device)\n",
    "        self.labels = data['Labels'].to(self.device)\n",
    "    \n",
    "    def forward(self):\n",
    "        # For each batch in the training set, forward method is called and\n",
    "        # outputs stored in fake_fits variable\n",
    "        self.fake_fits = self.net_G(self.inputs)\n",
    "        \n",
    "    def backward_D(self):\n",
    "        ''' Discriminator loss takes both target and input images.\n",
    "            loss_D_real is sigmoid cross-entropy loss of the target tensors and an array\n",
    "            of ones. \n",
    "            loss_D_fake is sigmoid cross-entropy loss of the input tensors and an\n",
    "            array of zeros.\n",
    "            Discriminator loss is loss_D = loss_D_real + loss_D_fake. '''\n",
    "        # Train the discriminator by feeding the fake images produced by the \n",
    "        # generator \n",
    "        fake_fits = self.fake_fits\n",
    "        fake_preds = self.net_D(fake_fits.detach()) # detach from generator's graph so they act like constants\n",
    "        # label the fake images as fake \n",
    "        self.loss_D_fake = self.GAN_loss(preds=fake_preds, target_is_real=False)\n",
    "        # Now feed a batch of real images from the training set and label them as real\n",
    "        real_fits = self.labels\n",
    "        real_preds = self.net_D(real_fits)\n",
    "        self.loss_D_real = self.GAN_loss(preds=real_preds, target_is_real=True)\n",
    "        # Add the two losses for fake and real, take the average and call backward()\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * .5\n",
    "        self.loss_D.backward()\n",
    "        self.discriminator_losses += [self.loss_D.item()]\n",
    "    \n",
    "    def backward_G(self):\n",
    "        ''' Generator loss is a sigmoid cross-entropy of input tensors and an \n",
    "            array of ones. Using the L1 loss, input tensors are structurally\n",
    "            similar to the target tensors.\n",
    "            Generator loss is defined as loss_G = loss_G_GAN + loss_G_L1*lambda_L1. '''\n",
    "        # Train the generator by feeding the discriminator the fake fits data and \n",
    "        # fool it by assigning real labels and calculating adversarial loss.\n",
    "        fake_fits = self.fake_fits\n",
    "        fake_preds = self.net_D(fake_fits.detach())\n",
    "        self.loss_G_GAN = self.GAN_loss(preds=fake_preds, target_is_real=True)\n",
    "        # Use L1 loss so tensors are not averaged over and compute the \n",
    "        # difference between the prediction and real and multiply \n",
    "        # by constant lambda \n",
    "        self.loss_G_L1 = self.L1_loss(self.fake_fits, self.labels) * self.lambda_L1\n",
    "        # Add L1 loss to the adversarial loss then call backward()\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "        self.generator_losses += [self.loss_G_GAN.item()]\n",
    "        \n",
    "    def optimise(self):\n",
    "        # Now optimise by the usual method of zeroing the gradients and calling\n",
    "        # step() on the optimiser\n",
    "        self.forward()\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "        \n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20848728",
   "metadata": {},
   "source": [
    "#### Helper Functions ####\n",
    "Below are the functions used to help visualise how the losses of the model are updated and to illustrate the performance of the model. The losses are logged and the results are shown with the help of these useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb0dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "    \n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def Create_Loss_Meters():\n",
    "    loss_D_fake = AverageMeter()\n",
    "    loss_D_real = AverageMeter()\n",
    "    loss_D = AverageMeter()\n",
    "    loss_G_GAN = AverageMeter()\n",
    "    loss_G_L1 = AverageMeter()\n",
    "    loss_G = AverageMeter()\n",
    "    \n",
    "    return {'loss_D_fake': loss_D_fake,\n",
    "            'loss_D_real': loss_D_real,\n",
    "            'loss_D': loss_D,\n",
    "            'loss_G_GAN': loss_G_GAN,\n",
    "            'loss_G_L1': loss_G_L1,\n",
    "            'loss_G': loss_G}\n",
    "\n",
    "# Update losses after each epoch\n",
    "def Update_Losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "    return loss_meter \n",
    "\n",
    "# Plot the losses for both the Generator and Discriminator\n",
    "def Loss_Plot(model, save=False):\n",
    "    gen_loss = model.generator_losses\n",
    "    dis_loss = model.discriminator_losses\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.plot(gen_loss, label='Generator Loss', color='red')\n",
    "    plt.plot(dis_loss, label='Discriminator Loss', color='blue', linestyle='--')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(f\"loss_{time.time()}.png\")\n",
    "\n",
    "# define a function to save the data (inputs and predicted values) in order to make SED plots\n",
    "def Save_Data(model, data):\n",
    "    # get the data\n",
    "    inputs = model.inputs.numpy()\n",
    "    fake_fits = model.fake_fits.detach().numpy()\n",
    "    real_fits = model.labels.numpy()\n",
    "    for i in range(len(model.inputs)):\n",
    "        # initialise a HDU\n",
    "        hdu1 = fits.ImageHDU()\n",
    "        # get the data and inverse the normalisation with the appropriate upper and lower values\n",
    "        hdu1.data = np.array(Inverse(inputs[i][0], f115w_lower, f115w_upper))\n",
    "        # write to a header\n",
    "        hdu1.header['Filter'] = 'F115W'\n",
    "        # write the data to the fits file\n",
    "        hdu1.writeto('f115w_input'+str(i)+'.fits', overwrite=True)\n",
    "        hdu2 = fits.ImageHDU()\n",
    "        hdu2.data = np.array(Inverse(inputs[i][1], f150w_lower, f150w_upper))\n",
    "        hdu2.header['Filter'] = 'F150W'\n",
    "        hdu2.writeto('f150w_input'+str(i)+'.fits', overwrite=True)\n",
    "        hdu3 = fits.ImageHDU()\n",
    "        hdu3.data = np.array(Inverse(inputs[i][2], f200w_lower, f200w_upper))\n",
    "        hdu3.header['Filter'] = 'F200W'\n",
    "        hdu3.writeto('f200w_input'+str(i)+'.fits', overwrite=True)\n",
    "    for j in range(len(model.labels)):\n",
    "        # save both the prediction and the ground truth LW fluxes to make comparison plots\n",
    "        hdu4_true = fits.ImageHDU()\n",
    "        hdu4_true.data = np.array(Inverse(real_fits[j][0], f277w_lower, f277w_upper))\n",
    "        hdu4_true.header['Filter'] = 'F277W'\n",
    "        hdu4_true.writeto('f277w_true'+str(j)+'.fits', overwrite=True)\n",
    "        hdu4_pred = fits.ImageHDU()\n",
    "        hdu4_pred.data = np.array(Inverse(fake_fits[j][0], f277w_lower, f277w_upper))\n",
    "        hdu4_pred.header['Filter'] = 'F277W'\n",
    "        hdu4_pred.writeto('f277w_out_pred'+str(j)+'.fits', overwrite=True)\n",
    "        hdu5_true = fits.ImageHDU()\n",
    "        hdu5_true.data = np.array(Inverse(real_fits[j][1], f356w_lower, f356w_upper))\n",
    "        hdu5_true.header['Filter'] = 'F356W'\n",
    "        hdu5_true.writeto('f356w_true'+str(j)+'.fits', overwrite=True)\n",
    "        hdu5_pred = fits.ImageHDU()\n",
    "        hdu5_pred.data = np.array(Inverse(fake_fits[j][1], f356w_lower, f356w_upper))\n",
    "        hdu5_pred.header['Filter'] = 'F356W'\n",
    "        hdu5_pred.writeto('f356w_out_pred'+str(j)+'.fits', overwrite=True)\n",
    "        hdu6_true = fits.ImageHDU()\n",
    "        hdu6_true.data = np.array(Inverse(real_fits[j][2], f444w_lower, f444w_upper))\n",
    "        hdu6_true.header['Filter'] = 'F444W'\n",
    "        hdu6_true.writeto('f444w_true'+str(j)+'.fits', overwrite=True)\n",
    "        hdu6_pred = fits.ImageHDU()\n",
    "        hdu6_pred.data = np.array(Inverse(fake_fits[j][2], f444w_lower, f444w_upper))\n",
    "        hdu6_pred.header['Filter'] = 'F444W'\n",
    "        hdu6_pred.writeto('f444w_out_pred'+str(j)+'.fits', overwrite=True)\n",
    "\n",
    "# Plots the result from the training set \n",
    "def Visualise_Train(model, data, save=True):\n",
    "    model.net_G.train()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    fake_fits = model.fake_fits.detach().permute(0,3,2,1)\n",
    "    real_fits = model.labels.permute(0,3,2,1)\n",
    "    inputs = model.inputs.permute(0,3,2,1)\n",
    "    fig = plt.figure(figsize=(16,11))\n",
    "    for i in range(4):\n",
    "        ax = plt.subplot(3, 4, i+1)\n",
    "        # Some cutouts contain a source that is too faint\n",
    "        # causing the data to be normalised as a zero vector.\n",
    "        try:\n",
    "            ax.imshow(inputs[i])\n",
    "            ax.set_title(r\"SW Channel [$0.6-2.3\\mu$m]\")\n",
    "            ax.axis(\"off\")\n",
    "        except IndexError:\n",
    "            continue\n",
    "        ax = plt.subplot(3, 4, i+1+4)\n",
    "        ax.imshow(fake_fits[i])\n",
    "        ax.set_title(\"Generated LW\")\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 4, i+1+8)\n",
    "        ax.imshow(real_fits[i])\n",
    "        ax.set_title(r\"Actual LW Channel [$2.4-5.0\\mu$m]\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(\"train.png\")\n",
    "\n",
    "# Plots to results from evaluating the model on the test set\n",
    "def Visualise_Test(model, data, save=True):\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.eval()\n",
    "    fake_fits = model.fake_fits.detach().permute(0,3,2,1)\n",
    "    real_fits = model.labels.permute(0,3,2,1)\n",
    "    inputs = model.inputs.permute(0,3,2,1)\n",
    "    fig = plt.figure(figsize=(12,11))\n",
    "    for i in range(3):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        try:\n",
    "            ax.imshow(inputs[i]) \n",
    "            ax.set_title(r\"SW Channel [$0.6-2.3\\mu$m]\")\n",
    "            ax.axis(\"off\")\n",
    "        except IndexError:\n",
    "            continue\n",
    "        ax = plt.subplot(3, 3, i+1+3)\n",
    "        ax.imshow(fake_fits[i])\n",
    "        ax.set_title(\"Generated LW\")\n",
    "        ax.axis(\"off\")\n",
    "        ax = plt.subplot(3, 3, i+1+6)\n",
    "        ax.imshow(real_fits[i])\n",
    "        ax.set_title(r\"Actual LW Channel [$2.4-5.0\\mu$m]\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "    if save:\n",
    "        fig.savefig(\"test2.png\")\n",
    "\n",
    "# Prints the results after each epoch\n",
    "def Log_Results(loss_meter_dict):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cee92c",
   "metadata": {},
   "source": [
    "#### Training Function ####\n",
    "The function below trains the model, feeding data from the training set for the model to learn features from. Here, we set the number of epochs for training. Training with 100 epochs is a recommendation, although, we already see results after 40 epochs. After each epoch, the weights are tuned further to the optimal weight for better model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6f66281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Model(model, trainloader, epochs, display_every=30):\n",
    "    print(\"Starting training....\")\n",
    "    start = time.time()\n",
    "    data = next(iter(trainloader)) # batch for visualising the model output after fixed intervals after training\n",
    "    for e in range(epochs):\n",
    "        # function returning a dictionary of objects to log the losses of the complete network\n",
    "        loss_meter_dict = Create_Loss_Meters() \n",
    "        i = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            model.setup_input(data)\n",
    "            model.optimise()\n",
    "            Update_Losses(model, loss_meter_dict, count=data['Inputs'].size(0)) # updates the log objects\n",
    "            i += 1\n",
    "        print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "        if i % display_every == 0: \n",
    "            print(f\"Iteration {i}/{len(trainloader)}\")\n",
    "        total_loss = Log_Results(loss_meter_dict) # function prints out the losses\n",
    "        print(total_loss)\n",
    "    Loss_Plot(model, save=True)\n",
    "    Visualise_Train(model, data)\n",
    "    endtime = time.time()\n",
    "    end = endtime - start\n",
    "    print(\"Time to train network: {:.2f}s\".format(end))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fef6d3",
   "metadata": {},
   "source": [
    "Each epoch takes between 3 to 4 minutes on a powerful GPU. The above code can be altered to test the model on the test set by setting the model to evaluation mode. An example of training the model is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c18179e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialised with norm initialisation\n",
      "model initialised with norm initialisation\n"
     ]
    }
   ],
   "source": [
    "model = GANModel()\n",
    "#Train_Model(model, trainloader, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f727e",
   "metadata": {},
   "source": [
    "### Results ###\n",
    "Below shows the model output on the training set after 100 epochs. \n",
    "\n",
    "![train](images/train_img.png)\n",
    "\n",
    "\n",
    "![test](images/test233.png)\n",
    "\n",
    "As we can see, the model has understanding of the features in the data and some colourisation. Although, we must see that the model is learning features such as a mostly black background with a central source for each item in the training set. \n",
    "Nevertheless, the model is a good baseline model for predicting longer wavebands and can be further implemented to predict sources in unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb8092",
   "metadata": {},
   "source": [
    "Below is an example plot of an SED of the far right galaxy in the image above plotted in red, with the predicted $LW$ fluxes plotted in blue. The cGAN is a good predictor of the SED."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e38db",
   "metadata": {},
   "source": [
    "![SED](images/SED_image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2ff28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu] *",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
